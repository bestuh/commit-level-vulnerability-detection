	count = be32_to_cpu(aclp->acl_cnt);
		}
	if (num_clips && clips_ptr) {
		clips = kzalloc(num_clips * sizeof(*clips), GFP_KERNEL);
static void iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)
	pch->chan_net = net;
	spin_unlock_bh(&pn->all_channels_lock);
		pointer_desc = "stack ";
		break;
	if (buf)
	nfs4_write_cached_acl(inode, pages, res.acl_data_offset, res.acl_len);
		_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);
		_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);
out_ok:
			regno, tn_buf);
	}
		struct vfio_irq_set hdr;
		u8 *data = NULL;
		int ret = 0;
		u8 *data = NULL;
		if (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||
		    hdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |
		if (!(hdr.flags & VFIO_IRQ_SET_DATA_NONE)) {
			size_t size;
			if (hdr.flags & VFIO_IRQ_SET_DATA_BOOL)
				size = sizeof(uint8_t);
			else if (hdr.flags & VFIO_IRQ_SET_DATA_EVENTFD)
				size = sizeof(int32_t);
			else
				return -EINVAL;
			if (hdr.argsz - minsz < hdr.count * size ||
				return -EINVAL;
	vdev->ctx = kzalloc(nvec * sizeof(struct vfio_pci_irq_ctx), GFP_KERNEL);
	if (!vdev->ctx)
	page = pte_page(huge_ptep_get((pte_t *)pmd));
	nid = page_to_nid(page);
	switch (opcode) {
	kvm_iommu_put_pages(kvm, slot->base_gfn, gfn);
static void kvm_unpin_pages(struct kvm *kvm, pfn_t pfn, unsigned long npages)
{
	unsigned long i;

	for (i = 0; i < npages; ++i)
		kvm_release_pfn_clean(pfn + i);
}

			/* if we knew anything about the old value, we're not
			 * equal, because we can't know anything about the
			 * scalar value of the pointer in the new value.
		} else {
			       tnum_is_unknown(rold->var_off);
		}
	unsigned long tpgt;
	int ret;
	if (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)
		return ERR_PTR(-EINVAL);
		return ERR_PTR(-EINVAL);
		sk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);
		sk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);
		hlist_add_head(&mp->mglist, &br->mglist);
	if (!port) {
		mod_timer(&mp->timer, now + br->multicast_membership_interval);
		*log_num = nlogs;
	return headcount;
			break;
{
{
static struct pernet_operations sctp_net_ops = {
	.init = sctp_net_init,
	.exit = sctp_net_exit,
};
	status = register_pernet_subsys(&sctp_net_ops);
	if (status)
		goto err_register_pernet_subsys;
	if (status)
	unregister_pernet_subsys(&sctp_net_ops);
err_register_pernet_subsys:
	unregister_pernet_subsys(&sctp_net_ops);
	strncpy(extra_response->key, key, strlen(key) + 1);
	strncpy(extra_response->value, NOTUNDERSTOOD,
			strlen(NOTUNDERSTOOD) + 1);
				char *tmpptr = key + strlen(key);
				*tmpptr = '=';
struct iscsi_extra_response {
	char key[64];
struct iscsi_extra_response {
	char value[32];
		get_net(peer);
	if (peer)
	char xbuf[12];
int lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
						t += 255;
					t += 15 + *ip++;
					}
				}
					t += 255;
				t += 31 + *ip++;
				}
					t += 255;
				t += 7 + *ip++;
				}
		ha->optrom_region_size = start + size > ha->optrom_size ?
		    ha->optrom_size - start : size;
		ha->optrom_region_start = start;
		ha->optrom_region_size = start + size > ha->optrom_size ?
		    ha->optrom_size - start : size;
		ha->optrom_region_start = start;
	if (tpgt > TL_TPGS_PER_HBA) {
		printk(KERN_ERR "Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:"
static int adjust_scalar_min_max_vals(struct bpf_verifier_env *env,
	if (BPF_CLASS(insn->code) != BPF_ALU64) {
		/* 32-bit ALU ops are (32,32)->64 */
		if (dst_reg->smin_value < 0) {
			if (umin_val) {
				dst_reg->smin_value = 0;
			} else {
				/* Lost sign bit information */
				dst_reg->smin_value = S64_MIN;
				dst_reg->smax_value = S64_MAX;
			}
			dst_reg->smin_value =
				(u64)(dst_reg->smin_value) >> umax_val;
		rp[0] = 1;
		res->nlimbs = (msize == 1 && mod->d[0] == 1) ? 0 : 1;
		res->sign = 0;
