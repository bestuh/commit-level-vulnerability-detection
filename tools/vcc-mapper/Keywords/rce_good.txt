	struct raw_frag_vec rfv;
	fe->frontend_priv = NULL;
}
	char *driver_override, *old = pdev->driver_override, *cp;
	if (strlen(driver_override)) {
	}
}
				return -EFAULT;
			}
	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
	freq_reg = devm_ioremap(dev, res->start, resource_size(res));
		rc = -EFAULT;
			sizeof(sipx->sipx_node));
		if (copy_to_user(arg, &ifr, sizeof(ifr)))
			break;
		if (copy_to_user(arg, &ifr, sizeof(ifr)))
		ipxitf_put(ipxif);
		rc = 0;
		pointer_desc = "stack ";
		break;
	if (copy_from_user(&u_ent.id, &uent->id, sizeof(u_ent.id)))
	{ecryptfs_opt_err, NULL}
{
	if (!options) {
		case ecryptfs_opt_err:
	int rc;
	if (rc) {
		unsigned long size = bprm->vma->vm_end - bprm->vma->vm_start;
		 * Limit to 1/4-th the stack size for the argv+env strings.
	} else if (ieee80211_is_action(mgmt->frame_control)) {
		af_params = kzalloc(sizeof(*af_params), GFP_KERNEL);
	struct v4l2_ext_control32 __user *ucontrols;
		unsigned size = sizeof(*ucontrols);
		/* Do not modify the pointer when copying a pointer control.
		   The contents of the pointer was changed, not the pointer
		   itself. */
			size -= sizeof(ucontrols->value64);
		if (copy_in_user(ucontrols, kcontrols, size))
{
{
	interval = muldiv64(val, NSEC_PER_SEC, KVM_PIT_FREQ);
int ib_update_cm_av(struct ib_cm_id *id, const u8 *smac, const u8 *alt_smac)
{

	cm_id_priv = container_of(id, struct cm_id_private, id);

	if (smac != NULL)
		memcpy(cm_id_priv->av.smac, smac, sizeof(cm_id_priv->av.smac));

	if (alt_smac != NULL)
		memcpy(cm_id_priv->alt_av.smac, alt_smac,
		       sizeof(cm_id_priv->alt_av.smac));

	return 0;
}
EXPORT_SYMBOL(ib_update_cm_av);

	u8 smac[ETH_ALEN];
	u8 alt_smac[ETH_ALEN];
	u8 *psmac = smac;
	u8 *palt_smac = alt_smac;
	int is_iboe = ((rdma_node_get_transport(cm_id->device->node_type) ==
			RDMA_TRANSPORT_IB) &&
		       (rdma_port_get_link_layer(cm_id->device,
			ib_event->param.req_rcvd.port) ==
			IB_LINK_LAYER_ETHERNET));
	if (is_iboe) {
		if (ib_event->param.req_rcvd.primary_path != NULL)
			rdma_addr_find_smac_by_sgid(
				&ib_event->param.req_rcvd.primary_path->sgid,
				psmac, NULL);
		else
			psmac = NULL;
		if (ib_event->param.req_rcvd.alternate_path != NULL)
			rdma_addr_find_smac_by_sgid(
				&ib_event->param.req_rcvd.alternate_path->sgid,
				palt_smac, NULL);
		else
			palt_smac = NULL;
	}
	if (is_iboe)
		ib_update_cm_av(cm_id, psmac, palt_smac);
int ib_update_cm_av(struct ib_cm_id *id, const u8 *smac, const u8 *alt_smac);
	usage = mem_cgroup_usage(memcg, type == _MEMSWAP);

	synchronize_rcu();
	mutex_unlock(&memcg->thresholds_lock);
	struct list_head auto_asconf_list;
		list_add_tail(&sp->auto_asconf_list,
	} else
		sp->do_auto_asconf = 1;
		sp->do_auto_asconf = 0;
		sp->do_auto_asconf = 0;
	struct list_head tmplist;
	if (oldsp->do_auto_asconf) {
		memcpy(&tmplist, &newsp->auto_asconf_list, sizeof(tmplist));
		memcpy(&newsp->auto_asconf_list, &tmplist, sizeof(tmplist));
	} else
	int i = 0;
{
	const struct msm_function *func = pctrl->soc->functions;
	for (; i <= pctrl->soc->nfunctions; i++)
		if (!strcmp(func[i].name, "ps_hold")) {
			free_ep_req(midi->out_ep, req);
	if (!to_vmx(vcpu)->nested.vmxon) {
		/* _system ok, as hardware has verified cpl=0 */
	/* ok to use *_system, as hardware has verified cpl=0 */
	fp->f_cred->user->unix_inflight++;
	fp->f_cred->user->unix_inflight--;
	if (!sock_flag(sk, SOCK_ZAPPED))
		return -EINVAL;
	if (!sock_flag(sk, SOCK_ZAPPED))
		return -EINVAL;
			struct media_pad_desc pad;
			media_device_kpad_to_upad(&entity->pads[p], &pad);
			media_device_kpad_to_upad(entity->links[l].source,
	if (tag == 0) {
	tag = data[dp++];
		dp += len;
		goto next_tag;
	}
	len = data[dp++];
	if (unlikely(n > sizeof(size_t) - 1))
	n = len - 0x80;
		goto length_too_long;
	for (len = 0; n > 0; n--) {
		goto data_overrun_error;
		len <<= 8;
	}
	dp += len;
		gctx = group_leader->ctx;
		mutex_lock_double(&gctx->mutex, &ctx->mutex);
	kvm_iommu_put_pages(kvm, slot->base_gfn, gfn);
static void kvm_unpin_pages(struct kvm *kvm, pfn_t pfn, unsigned long npages)
{
	unsigned long i;

	for (i = 0; i < npages; ++i)
		kvm_release_pfn_clean(pfn + i);
}

		disconnect = !IS_MNT_LOCKED_AND_LAZY(p);
		else umount_tree(mnt, 0);
		}
	for (i = 0; i <= SERDES_MAX; i++) {
		struct serdes_macro *macro = phy_get_drvdata(ctrl->phys[i]);
	for (i = 0; i <= SERDES_MAX; i++) {
		ret = serdes_phy_create(ctrl, i, &ctrl->phys[i]);
			if (iter > CIPSO_V4_TAG_MAXCNT)
		if (nla->nla_type == NLBL_CIPSOV4_A_TAG) {
				return -EINVAL;
		}
	while (ret < nr) {
		bh->b_size = map.m_len << inode->i_blkbits;
		bh->b_state = (bh->b_state & ~F2FS_MAP_FLAGS) | map.m_flags;
	}
	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
	skb->len = hdrlen + per_fragm;
	return 0;
					 io_data->req->actual;
	io_data->kiocb->private = NULL;
		if (cs > CQSPI_MAX_CHIPSELECT) {
			dev_err(dev, "Chip select %d out of range.\n", cs);
			}
#define transparent_hugepage_defrag(__vma)				\
		sk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);
		sk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);
usbtv_audio_fail:
	usbtv_video_free(usbtv);
		sgl = list_first_entry(&ctx->tsgl,
				       struct skcipher_sg_list, list);
		sg = sgl->sg;

		while (!sg->length)
			sg++;

	bprm->recursion_depth++; /* Well, the bang-shell is implicit... */
	if (bprm->recursion_depth > BINPRM_MAX_RECURSION)
	bprm->recursion_depth++;
	if ((bprm->buf[0] != '#') || (bprm->buf[1] != '!') ||
	    (bprm->recursion_depth > BINPRM_MAX_RECURSION))
	bprm->recursion_depth++;
#define BINPRM_MAX_RECURSION 4
		sk_mem_reclaim(sk);
		if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf &&
		    !tcp_under_memory_pressure(sk))
			break;
	if ((err = xfrm_migrate_check(m, num_migrate)) < 0)
	ext3_msg(sb, "error: failed to open journal device %s: %ld",
		ext3_msg(sb, "error: invalid sb specification: %s",
	if (A > skb->len - sizeof(struct nlattr))
	if (A > skb->len - sizeof(struct nlattr))
	if (nla->nla_len > A - skb->len)
	nla = (struct nlattr *) &skb->data[A];
		return 0;
#define pte_valid_ng(pte) \
	((pte_val(pte) & (PTE_VALID | PTE_NG)) == (PTE_VALID | PTE_NG))
	if (pte_valid_ng(pte)) {
	 * occurred.
	unsigned long vm_flags = VM_READ | VM_WRITE;
	if (count > PATH_MAX)
		return -EINVAL;
{
{
static struct pernet_operations sctp_net_ops = {
	.init = sctp_net_init,
	.exit = sctp_net_exit,
};
	status = register_pernet_subsys(&sctp_net_ops);
	if (status)
		goto err_register_pernet_subsys;
	if (status)
	unregister_pernet_subsys(&sctp_net_ops);
err_register_pernet_subsys:
	unregister_pernet_subsys(&sctp_net_ops);
	if (type == HUB_INIT2)
		goto init2;
	if (type == HUB_INIT3)
		goto init3;
		goto init3;
					msecs_to_jiffies(delay));
			return;		/* Continues at init3: below */
int sysctl_tcp_challenge_ack_limit = 100;
	if (now != challenge_timestamp) {
		challenge_timestamp = now;
		challenge_timestamp = now;
	if (++challenge_count <= sysctl_tcp_challenge_ack_limit) {
			remote_efs = 1;
			if (olen == sizeof(efs))
		case L2CAP_CONF_EFS:
				memcpy(&efs, (void *) val, olen);
				memcpy(&efs, (void *) val, olen);
				memcpy(&efs, (void *)val, olen);
			if (chan->local_stype != L2CAP_SERV_NOTRAFIC &&
			    efs.stype != L2CAP_SERV_NOTRAFIC &&
	nlk->cb_running = false;
	consume_skb(cb->skb);
		ret = -EINVAL;
		if (!asma->file) {
		}
		break;
	struct amba_device *dev = to_amba_device(_dev);
}
	struct amba_device *dev = to_amba_device(_dev);
	if (strlen(driver_override)) {
	}
	free = __LOG_BUF_LEN - log_end;
		unsigned log_idx_mask = start & (__LOG_BUF_LEN - 1);

		log_buf[dest_idx] = __log_buf[log_idx_mask];
	new_log_buf_len = 0;
	rwlock_t rq_list_lock;	/* protect access to list in req_arr */
	int timeout;		/* defaults to SG_DEFAULT_TIMEOUT      */
	char mmap_called;	/* 0 -> mmap() never called on this fd */
static int sg_res_in_use(Sg_fd * sfp);
	__get_user(opcode, buf);
	if (sfp->next_cmd_len > 0) {
	}
		if (sg_res_in_use(sfp)) {
		}
			sg_remove_request(sfp, srp);
		if (val != sfp->reserve.bufflen) {
			if (sg_res_in_use(sfp) || sfp->mmap_called)
		if (val != sfp->reserve.bufflen) {
				return -EBUSY;
				return -EBUSY;
		}
		return 0;
			sg_link_reserve(sfp, srp, dxfer_len);
			sg_link_reserve(sfp, srp, dxfer_len);
			res = sg_build_indirect(req_schp, sfp, dxfer_len);
			res = sg_build_indirect(req_schp, sfp, dxfer_len);
	sfp->timeout = SG_DEFAULT_TIMEOUT;
static int
sg_res_in_use(Sg_fd * sfp)
{
	const Sg_request *srp;
	unsigned long iflags;

	read_lock_irqsave(&sfp->rq_list_lock, iflags);
	for (srp = sfp->headrp; srp; srp = srp->nextrp)
		if (srp->res_used)
			break;
	read_unlock_irqrestore(&sfp->rq_list_lock, iflags);
	return srp ? 1 : 0;
}

	mov	\tmp1, #0
	mcr	p15, 0, \tmp1, c13, c0, 2	@ clear user r/w TLS register
	movne	\tmp1, #0
	mcrne	p15, 0, \tmp1, c13, c0, 2	@ clear user r/w TLS register
	char *driver_override, *old = pdev->driver_override, *cp;
	if (strlen(driver_override)) {
	}
	return sprintf(buf, "%s\n", pdev->driver_override);
}
		if (devnr > AD5755_NUM_CHANNELS) {
	for_each_child_of_node(np, pp) {
			dev_err(dev,
	ret = call_bufop(q, verify_planes_array, *vb, pb);
	if (!ret)
static struct mount *last_dest, *last_source, *dest_master;
static struct user_namespace *user_ns;
static struct mountpoint *mp;
		struct mount *n, *p;
		for (n = m; ; n = p) {
			if (p == dest_master || IS_MNT_MARKED(p)) {
				while (last_dest->mnt_master != p) {
					last_source = last_source->mnt_master;
					last_dest = last_source->mnt_parent;
				}
					last_source = last_source->mnt_master;
					last_dest = last_source->mnt_parent;
			p = n->mnt_master;
				break;
		type = CL_SLAVE;
	last_dest = dest_mnt;
	last_source = source_mnt;
	memcpy(&config->desc, buffer, USB_DT_CONFIG_SIZE);
	if (config->desc.bDescriptorType != USB_DT_CONFIG ||
	nintf = nintf_orig = config->desc.bNumInterfaces;
	char xbuf[12];
			len = list->tail - list->head;
			len = HID_DEBUG_BUFSIZE - list->head;
			goto copy_rest;
			ret += len;
		}
int lzo1x_decompress_safe(const unsigned char *in, size_t in_len,
						t += 255;
					t += 15 + *ip++;
					}
				}
					t += 255;
				t += 31 + *ip++;
				}
					t += 255;
				t += 7 + *ip++;
				}
	other = unix_peer_get(sk);
	if (other) {
		if (unix_peer(other) != sk) {
			if (unix_recvq_full(other))
				writable = 0;
		}
		sock_put(other);
	writable = unix_writable(sk);
	}
	if (tpgt > TL_TPGS_PER_HBA) {
		printk(KERN_ERR "Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:"
	} else if (keyring == new->session_keyring) {
		ret = 0;
		if (len < 0 || addr.nl_pid) {
			syslog(LOG_ERR, "recvfrom failed; pid:%u error:%d %s",
		ptr = (void *)val;
	}
#define NVIF_IOCTL_V0_OWNER_NVIF                                           0x00
#define NVIF_IOCTL_V0_OWNER_ANY                                            0xff
	__u8  owner;
	__u8  path_nr;
	__u8  type;
#define NVIF_IOCTL_V0_ROUTE_NVIF                                           0x00
	__u8  pad04[3];
	__u32 path[8];		/* in reverse */
	__u64 token;
	__u8  data[];		/* ioctl data (below) */
	__u64 token;
	__u32 handle;
				   "route %02x token %llx\n",
		   args->v0.version, _handle, _oclass,
		   args->v0.route, args->v0.token);
		   args->v0.version, _handle, _oclass,
fail_handle:
static int
{
	int ret;
	while ((object = parent->object), nr--) {
		if (!nv_iclass(object, NV_PARENT_CLASS)) {
			return -EINVAL;
		}

		if (!(namedb = (void *)nv_pclass(object, NV_NAMEDB_CLASS)) ||
			return -ENOENT;
		}
		parent = handle;
	}
		return -EACCES;
	*route = handle->route;
	*token = handle->token;
	}
			ret = nvkm_ioctl_v0[type].func(handle, data, size);
	}
			   args->v0.version, args->v0.type, args->v0.path_nr,
	if (nvif_unpack(args->v0, 0, 0, true)) {
			   args->v0.owner);
		ret = nvkm_ioctl_path(client->root, args->v0.type,
				      args->v0.path_nr, args->v0.path,
			   args->v0.owner);
				      data, size, args->v0.owner,
	dev_hold(dev);
static void snd_compr_update_tstamp(struct snd_compr_stream *stream,
		struct snd_compr_tstamp *tstamp)
		return;
	if (!stream->ops->pointer)
	stream->ops->pointer(stream, tstamp);
	stream->runtime->total_bytes_transferred = tstamp->copied_total;
}
	snd_compr_update_tstamp(stream, &avail->tstamp);
	snd_compr_update_tstamp(stream, &avail->tstamp);
	struct snd_compr_tstamp tstamp;
{
	snd_compr_update_tstamp(stream, &tstamp);
	return copy_to_user((struct snd_compr_tstamp __user *)arg,
		&tstamp, sizeof(tstamp)) ? -EFAULT : 0;
}
	}
	mlx4_dbg(dev, "Free MAC index is %d\n", free);
	if (table->total == table->max) {
		rp[0] = 1;
		res->nlimbs = (msize == 1 && mod->d[0] == 1) ? 0 : 1;
		res->sign = 0;
